# Duplicate Prevention Implementation: Complexity & Risk Analysis
**Date**: January 21, 2026
**Assessment**: Medium complexity, Low-Medium risk

---

## Complexity Analysis

### Layer 1: In-Memory Session Check ‚≠ê (SIMPLE)

**Complexity**: **Very Low** (1-2 hours)

**What's Needed**:
```javascript
// Add ONE state variable to IndividualPurchase.jsx
const [usedPassportsInBatch, setUsedPassportsInBatch] = useState(new Set());

// Add ONE check in passport registration
if (usedPassportsInBatch.has(passportKey)) {
  toast({ title: "Duplicate in this batch" });
  return;
}

// Add ONE line after successful registration
setUsedPassportsInBatch(prev => new Set([...prev, passportKey]));
```

**Files to Modify**: 1 file (IndividualPurchase.jsx)
**New Dependencies**: None
**Backend Changes**: None
**Database Changes**: None

**Risk**: **Negligible**
- Pure frontend logic
- No external dependencies
- Cannot break existing functionality
- Easy to test
- Easy to rollback (just remove 3 lines)

---

### Layer 2: IndexedDB Browser Cache ‚≠ê‚≠ê (MODERATE)

**Complexity**: **Low-Medium** (4-8 hours)

**What's Needed**:
1. Install `idb` package (npm install idb)
2. Create new service file: `src/lib/voucherCacheService.js` (~200 lines)
3. Integrate into IndividualPurchase.jsx (~30 lines added)
4. Add online/offline event listeners (~20 lines)

**Files to Create**: 1 file
**Files to Modify**: 1 file
**New Dependencies**: 1 package (`idb` - 3KB, widely used)
**Backend Changes**: None initially
**Database Changes**: None

**Risk**: **Low**
- Established library (`idb` is maintained by Google Chrome team)
- Isolated service (doesn't affect other features)
- Works in parallel with existing code
- Graceful degradation (if IndexedDB fails, app still works)
- Browser support: 95%+ (all modern browsers)

**Potential Issues**:
- Browser storage quota (~50MB typical, 1GB+ available)
- User clears browser data (cache rebuilds from backend)
- Private/incognito mode (IndexedDB may be disabled - falls back to Layer 1)

**Mitigations**:
- Store only 24 hours of data (~1-2MB max)
- Graceful fallback to in-memory check
- Auto-rebuild from backend when online

---

### Layer 3: Backend Database Check ‚≠ê‚≠ê‚≠ê (MODERATE-HIGH)

**Complexity**: **Medium** (8-12 hours)

**What's Needed**:

#### Backend Changes
1. **Add feature flag logic** to `register-passport` endpoint (~50 lines)
2. **Add duplicate check query** with timeout wrapper (~30 lines)
3. **Add environment variable** handling
4. **Create backend sync endpoint** for cache (~100 lines)
   - `GET /api/vouchers/recent?hours=24`
   - Returns recent vouchers for cache rebuild
5. **Add audit logging** for offline registrations (~40 lines)

**Files to Modify**:
- `backend/routes/public-purchases.js`
- `backend/.env` (add variables)

**Files to Create**:
- Optional: `backend/routes/vouchers.js` enhancement (sync endpoint)

**New Dependencies**: None (use existing PostgreSQL)
**Database Changes**:
- Optional: Add index on `(passport_number, nationality, status, valid_until)` for performance
- Optional: Create `audit_log` table (if doesn't exist)

**Risk**: **Medium**
- Timeout logic needs careful testing
- Feature flag must be bulletproof
- Database query must be optimized (add index)
- Network errors must be handled gracefully

**Potential Issues**:
1. **Timeout too short**: Rejects valid registrations
2. **Timeout too long**: Kiosk hangs when offline
3. **Database lock**: Concurrent registrations might deadlock
4. **Feature flag mistake**: Production blocks all registrations or allows all duplicates

**Mitigations**:
- Configurable timeout (default 5 seconds, adjustable)
- Promise.race() pattern prevents hanging
- Use SELECT ... FOR UPDATE SKIP LOCKED (no deadlocks)
- Test feature flag thoroughly in staging
- Add logging/monitoring for flag state

---

## Overall Complexity Rating

### Phased Approach (RECOMMENDED)

**Phase 1**: Layer 1 only (In-Memory)
- **Complexity**: ‚≠ê Very Low
- **Time**: 1-2 hours
- **Risk**: Negligible
- **Coverage**: 80% of duplicate errors (same session)
- **Deploy**: Immediately

**Phase 2**: Layer 1 + Layer 2 (+ IndexedDB)
- **Complexity**: ‚≠ê‚≠ê Low-Medium
- **Time**: 6-10 hours total
- **Risk**: Low
- **Coverage**: 95% of duplicates (24-hour window, offline)
- **Deploy**: After 1 week of Phase 1 testing

**Phase 3**: All Layers (+ Backend)
- **Complexity**: ‚≠ê‚≠ê‚≠ê Medium
- **Time**: 14-20 hours total
- **Risk**: Medium
- **Coverage**: 99.9% of duplicates (full protection)
- **Deploy**: After 2 weeks of Phase 2 testing

### All-at-Once Approach (Higher Risk)

- **Complexity**: ‚≠ê‚≠ê‚≠ê‚≠ê Medium-High
- **Time**: 16-24 hours
- **Risk**: Medium-High
- **Coverage**: 99.9% from day 1
- **Deploy**: After extensive testing

**Recommendation**: **Phased approach** - lower risk, faster time-to-value

---

## Risk Assessment by Category

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| IndexedDB not supported in browser | Low (5%) | Medium | Fallback to Layer 1 only |
| User clears browser data | Medium (20%) | Low | Auto-rebuild from backend |
| Database timeout too aggressive | Medium (15%) | Medium | Configurable timeout, testing |
| Backend query slow (no index) | High (60%) | High | **Add database index first** |
| Feature flag wrong state | Low (10%) | Critical | Environment variable validation, logging |
| Concurrent registration race condition | Low (5%) | Medium | Use SKIP LOCKED, test with load |
| Network timeout hangs UI | Medium (20%) | Medium | Promise.race(), 5-second max |

### Operational Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Agent confused by error messages | Medium (25%) | Low | Clear, actionable messages |
| Testing mode left on in production | Low (5%) | Critical | **Automated checks, monitoring** |
| Offline mode allows fraud duplicates | Low (10%) | Medium | Audit log review, 24-hour cache |
| False positives block valid users | Medium (15%) | High | Manual override for IT_Support role |
| Cache and DB out of sync | Low (10%) | Low | Auto-sync on reconnect |

### Business Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Legitimate duplicate use case rejected | Low (5%) | Medium | Document business rules clearly |
| Regulatory compliance issue | Very Low (2%) | High | Audit trail for all duplicates |
| User experience degradation | Low (10%) | Medium | Fast local checks, clear messages |
| Revenue loss from false blocks | Very Low (3%) | High | Manual override, support escalation |

---

## What Could Go Wrong? (Worst-Case Scenarios)

### Scenario 1: Database Index Missing
**Problem**: Backend check takes 15+ seconds
**Result**: All registrations timeout, fall back to cache-only
**Impact**: ‚ö†Ô∏è Medium - System still works, but no cross-kiosk duplicate prevention
**Fix**: Add index, restart backend (5 minutes)

**Prevention**:
```sql
-- Add before deployment
CREATE INDEX CONCURRENTLY idx_vouchers_duplicate_check
ON individual_purchases (passport_number, nationality, status, valid_until)
WHERE status IN ('VALID', 'PENDING');
```

### Scenario 2: Feature Flag Misconfigured
**Problem**: `ALLOW_DUPLICATE_PASSPORTS=false` typo as `fals`
**Result**: JavaScript reads as string, evaluates to truthy, duplicates allowed
**Impact**: üî¥ Critical - Production allows duplicates
**Fix**: Correct .env, restart (2 minutes)

**Prevention**:
```javascript
// Strict boolean parsing with validation
const ALLOW_DUPLICATE_PASSPORTS = (() => {
  const value = process.env.ALLOW_DUPLICATE_PASSPORTS;
  if (value !== 'true' && value !== 'false') {
    console.error(`INVALID ALLOW_DUPLICATE_PASSPORTS: "${value}" - defaulting to false`);
    return false;
  }
  return value === 'true';
})();

// Log on startup
console.log(`[CONFIG] Duplicate passports: ${ALLOW_DUPLICATE_PASSPORTS ? 'ALLOWED (testing)' : 'BLOCKED (production)'}`);
```

### Scenario 3: IndexedDB Storage Full
**Problem**: Browser storage quota exceeded (rare)
**Result**: Cache writes fail, throws exception
**Impact**: ‚ö†Ô∏è Medium - Registrations might fail if not caught
**Fix**: Graceful error handling

**Prevention**:
```javascript
try {
  await cacheVoucherRegistration(passport, voucher);
} catch (error) {
  console.warn('Cache write failed (storage full?):', error);
  // Continue anyway - backend registration still succeeded
}
```

### Scenario 4: Network Timeout During Peak Hours
**Problem**: Internet slow (10+ seconds), timeout at 5 seconds
**Result**: All backend checks timeout, rely on cache
**Impact**: ‚ö†Ô∏è Low-Medium - Most duplicates still caught by cache (24 hours)
**Fix**: Adjust timeout in .env, monitor network quality

**Prevention**:
- Start with conservative timeout (5 seconds)
- Monitor timeout rate in logs
- Adjust based on real PNG network conditions
- Consider dynamic timeout based on recent latency

### Scenario 5: Agent Uses Incognito Mode
**Problem**: IndexedDB disabled in private browsing
**Result**: Only Layer 1 (in-memory) works
**Impact**: ‚ö†Ô∏è Low - Still catches duplicates in same session
**Fix**: None needed - acceptable degradation

**Prevention**:
```javascript
// Detect and warn
const isIncognito = await detectIncognitoMode();
if (isIncognito) {
  console.warn('Private browsing detected - duplicate prevention limited to current session');
  // Optionally show one-time notice to agent
}
```

---

## Testing Complexity

### Unit Tests (Simple)
```javascript
describe('Duplicate Prevention', () => {
  test('Layer 1: Blocks duplicate in same batch', () => {
    // Simple React state test
  });

  test('Layer 2: IndexedDB cache', async () => {
    // Mock idb, test cache logic
  });

  test('Layer 3: Backend check with timeout', async () => {
    // Mock fetch with timeout
  });
});
```

**Effort**: 4-6 hours
**Tools**: Jest, React Testing Library (already in project)

### Integration Tests (Moderate)
```javascript
describe('End-to-End Duplicate Prevention', () => {
  test('Register passport, try duplicate, should block', async () => {
    // Playwright test
  });

  test('Offline mode: IndexedDB prevents duplicate', async () => {
    // Simulate offline, test cache
  });

  test('Feature flag: Testing mode allows duplicate', async () => {
    // Change env var, test behavior
  });
});
```

**Effort**: 6-8 hours
**Tools**: Playwright (already in project)

### Manual Testing (Critical)
**Checklist**: 20-30 test cases
**Effort**: 4-8 hours
**Required**: Yes - network conditions, browser compatibility, timeout tuning

---

## Dependencies & Compatibility

### New Dependencies

| Package | Size | Risk | Alternatives |
|---------|------|------|--------------|
| `idb` (IndexedDB wrapper) | 3KB | Very Low | Native IndexedDB (more complex), Dexie.js (heavier) |

**Total added weight**: ~3KB (negligible)

### Browser Compatibility

| Browser | Layer 1 | Layer 2 (IndexedDB) | Layer 3 |
|---------|---------|---------------------|---------|
| Chrome 90+ | ‚úÖ | ‚úÖ | ‚úÖ |
| Firefox 88+ | ‚úÖ | ‚úÖ | ‚úÖ |
| Safari 14+ | ‚úÖ | ‚úÖ | ‚úÖ |
| Edge 90+ | ‚úÖ | ‚úÖ | ‚úÖ |
| Mobile Safari | ‚úÖ | ‚úÖ | ‚úÖ |
| Mobile Chrome | ‚úÖ | ‚úÖ | ‚úÖ |
| IE 11 | ‚úÖ | ‚ö†Ô∏è Polyfill needed | ‚úÖ |

**PNG Airport Kiosks**: Likely modern Chrome/Edge - full support

### Backend Compatibility

- **PostgreSQL 12+**: ‚úÖ Full support (SKIP LOCKED)
- **PostgreSQL 9.6-11**: ‚ö†Ô∏è Limited (no SKIP LOCKED, may deadlock under load)
- **PostgreSQL 9.5 or older**: ‚ùå Upgrade required

**Current production**: PostgreSQL version? (check with `SELECT version();`)

---

## Performance Impact

### Layer 1: In-Memory
- **CPU**: Negligible (Set.has() is O(1), <1ms)
- **Memory**: ~100 bytes per passport in batch (max 5-10 passports)
- **Network**: None
- **Impact**: **Zero** - imperceptible

### Layer 2: IndexedDB
- **CPU**: Very Low (indexed lookup, ~5-10ms)
- **Memory**: ~2MB for 24-hour cache (1000 vouchers @ 2KB each)
- **Disk**: ~2MB in browser storage
- **Network**: Initial sync only (when online)
- **Impact**: **Negligible** - <10ms per check

### Layer 3: Backend
- **Database CPU**: Low with index, High without
  - With index: ~1-5ms query time
  - Without index: ~100-500ms query time (sequential scan)
- **Network**: 1 round-trip (~100-300ms PNG latency)
- **Timeout overhead**: Max 5 seconds if offline
- **Impact**: **Low** when online, **Medium** when offline (timeout delay)

**Critical**: Must add database index BEFORE enabling Layer 3

```sql
-- MUST RUN BEFORE DEPLOYMENT
CREATE INDEX CONCURRENTLY idx_vouchers_duplicate_check
ON individual_purchases (passport_number, nationality, status, valid_until)
WHERE status IN ('VALID', 'PENDING');

-- Verify index is used
EXPLAIN ANALYZE
SELECT * FROM individual_purchases
WHERE passport_number = 'P61820835'
  AND nationality = 'DNK'
  AND status IN ('VALID', 'PENDING')
  AND valid_until > NOW();

-- Should show: "Index Scan using idx_vouchers_duplicate_check"
```

---

## Deployment Complexity

### Phase 1: Layer 1 Only (EASY)
```bash
# Frontend only
npm run build
# Upload dist/ to server
# No backend changes, no database changes, no .env changes
```

**Risk**: Very Low
**Time**: 10 minutes
**Rollback**: Delete 3 lines of code

### Phase 2: Add Layer 2 (MODERATE)
```bash
# Frontend
npm install idb
npm run build
# Upload dist/ to server

# No backend changes yet
```

**Risk**: Low
**Time**: 15 minutes
**Rollback**: Remove idb package, rebuild

### Phase 3: Add Layer 3 (COMPLEX)
```bash
# 1. Database index (MUST DO FIRST)
psql -c "CREATE INDEX CONCURRENTLY idx_vouchers_duplicate_check ..."

# 2. Backend .env changes
echo "ALLOW_DUPLICATE_PASSPORTS=false" >> .env

# 3. Backend code deploy
# Upload backend/routes/public-purchases.js
pm2 restart greenpay-api

# 4. Frontend rebuild (if sync endpoint added)
npm run build
# Upload dist/

# 5. Verify
curl https://greenpay.eywademo.cloud/api/health
# Check logs for config message
```

**Risk**: Medium
**Time**: 30-45 minutes
**Rollback**:
1. Set `ALLOW_DUPLICATE_PASSPORTS=true`
2. Restart backend
3. Revert backend code

---

## Alternative: Simpler Approach

If the full three-layer solution seems too complex, consider this **minimalist approach**:

### Simplified Strategy: Layer 1 + Feature Flag Backend Only

**Frontend** (5 hours):
- In-memory duplicate check in current batch

**Backend** (4 hours):
- Feature flag: `ALLOW_DUPLICATE_PASSPORTS`
- Simple backend check (no timeout, just try/catch)
- If database fails ‚Üí allow registration (graceful degradation)

**Total Effort**: ~9 hours
**Risk**: Low
**Coverage**: 80% duplicates caught, 100% when online

**Code**:
```javascript
// Frontend: Just Layer 1
const [usedInBatch] = useState(new Set());
if (usedInBatch.has(passport)) return;

// Backend: Simple check
if (!ALLOW_DUPLICATE_PASSPORTS) {
  try {
    const exists = await quickCheck(passport);
    if (exists) return res.status(409).json({ error: 'Duplicate' });
  } catch {
    console.warn('DB check failed, allowing');
    // Continue - better to allow than to block when offline
  }
}
```

**Trade-off**:
- ‚ùå No persistent cache (duplicates possible after browser refresh)
- ‚ùå No 24-hour offline protection
- ‚úÖ Much simpler (50% less code)
- ‚úÖ Faster to implement
- ‚úÖ Easier to maintain

---

## Recommended Approach

### For PNG Production Reality

Given:
- Unstable internet connectivity
- Need for testing flexibility
- Limited development time
- High reliability requirements

**Recommendation**: **Phased rollout with simplified Layer 2**

### Week 1-2: Layer 1 Only
- In-memory batch check
- Deploy immediately
- Catches 80% of duplicates (agent mistakes)
- Zero risk, zero complexity

### Week 3-4: Add Simplified Backend Check
- Feature flag in .env
- Simple database query with try/catch
- No IndexedDB complexity
- Covers remaining 15% (cross-kiosk duplicates)

### Month 2: Evaluate if IndexedDB needed
- Review duplicate attempt logs
- If offline duplicates are rare ‚Üí skip Layer 2
- If offline duplicates are frequent ‚Üí add Layer 2

**Total Effort**:
- Week 1-2: 2 hours
- Week 3-4: 6 hours
- Optional Month 2: 8 hours
- **Total: 8-16 hours** (vs. 20+ for full implementation)

---

## Decision Matrix

| Approach | Complexity | Risk | Coverage | Time | Best For |
|----------|------------|------|----------|------|----------|
| **Layer 1 only** | ‚≠ê Very Low | Very Low | 80% | 2h | Immediate fix |
| **Layer 1 + Backend** | ‚≠ê‚≠ê Low | Low | 95% | 8h | Production ready |
| **Layer 1 + 2 (IndexedDB)** | ‚≠ê‚≠ê Medium | Low | 95% offline | 10h | Unreliable network |
| **All 3 layers** | ‚≠ê‚≠ê‚≠ê Medium-High | Medium | 99.9% | 20h | Mission critical |
| **Full + monitoring** | ‚≠ê‚≠ê‚≠ê‚≠ê High | Medium | 99.9%+ | 30h | Enterprise grade |

---

## Final Recommendation

**START WITH**: Layer 1 + Simple Backend Check (8 hours total)

**Reasoning**:
1. ‚úÖ Solves 95% of the problem
2. ‚úÖ Low complexity, low risk
3. ‚úÖ Works with PNG's network reality
4. ‚úÖ Feature flag for testing flexibility
5. ‚úÖ Can add IndexedDB later if needed
6. ‚úÖ Proven pattern (used by many airports)

**ADD LATER** (if needed): IndexedDB Layer 2
- Only if offline duplicates become a problem
- After monitoring real-world usage
- When you have more development bandwidth

**Questions to Answer**:
1. What PostgreSQL version is production running? (affects index strategy)
2. How often is internet down at airport? (affects need for offline cache)
3. What's the testing timeline? (affects phased vs. all-at-once)
4. Who can approve feature flag changes? (affects deployment process)

Want me to implement the recommended 8-hour approach (Layer 1 + Simple Backend)?
